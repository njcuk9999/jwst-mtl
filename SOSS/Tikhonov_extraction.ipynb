{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of an extraction using tikhonov regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Explain what tikhonov regularisation is and why we use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages.\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "\n",
    "# Imports from the extraction.\n",
    "from extract.overlap import TrpzOverlap\n",
    "from extract.throughput import ThroughputSOSS\n",
    "from extract.convolution import WebbKer\n",
    "\n",
    "# Imports for plots\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm  # For displaying of FITS images.\n",
    "# TODO astropy has some nice functions for colorbars scaling of astronomical data, might be worth looking into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(13,8)) \n",
    "plt.rc('font', size=16)\n",
    "plt.rc('image', cmap='inferno')\n",
    "plt.rc('lines', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read relevant files TODO maybe we could make a a function that does this in utils?\n",
    "# ANSWER : Yes, should we do it with the spacetel framework (so not now)?\n",
    "\n",
    "# List of orders to consider in the extraction\n",
    "order_list = [1,2]\n",
    "\n",
    "#### Wavelength solution ####\n",
    "wave_maps = []\n",
    "wave_maps.append(fits.getdata(\"extract/Ref_files/wavelengths_m1.fits\"))\n",
    "wave_maps.append(fits.getdata(\"extract/Ref_files/wavelengths_m2.fits\"))\n",
    "\n",
    "#### Spatial profiles ####\n",
    "spat_pros = []\n",
    "spat_pros.append(fits.getdata(\"extract/Ref_files/spat_profile_m1.fits\").squeeze())\n",
    "spat_pros.append(fits.getdata(\"extract/Ref_files/spat_profile_m2.fits\").squeeze())\n",
    "\n",
    "# Convert data from fits files to float (fits precision is 1e-8)\n",
    "wave_maps = [wv.astype('float64') for wv in wave_maps]\n",
    "spat_pros = [p_ord.astype('float64') for p_ord in spat_pros]\n",
    "\n",
    "#### Throughputs ####\n",
    "thrpt_list = [ThroughputSOSS(order) for order in order_list] \n",
    "\n",
    "#### Convolution kernels ####\n",
    "ker_list = [WebbKer(wv_map) for wv_map in wave_maps]\n",
    "\n",
    "# Put all inputs from reference files in a list\n",
    "ref_files_args = [spat_pros, wave_maps, thrpt_list, ker_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read some ref files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom function to read toy simulation\n",
    "from sys import path  # TODO all import should be at the top. \n",
    "# Answer: this is temporary since we should have better simulations eventually\n",
    "#         and my format was very custom. That's why I let this whole section\n",
    "#         in a separate bloc.\n",
    "path.append(\"Fake_data\")\n",
    "from simu_utils import load_simu  # TODO can this function be moved to utils?\n",
    "# Answer: same as previous comment: very custom format. Should be changed.\n",
    "# Load a simulation\n",
    "simu = load_simu(\"Fake_data/phoenix_teff_02300_scale_1.0e+02.fits\")\n",
    "data = simu[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction Parameters\n",
    "(Example usage with few inputs parameters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "# Map of expected noise (standard deviation).\n",
    "bkgd_noise = 20.  # In counts?\n",
    "\n",
    "# Wavelength extraction grid oversampling.\n",
    "params[\"n_os\"] = 5  # TODO explain a bit more how the grid is determined?\n",
    "# Answer: I was thinking of explaining all inputs in another notebook or text?\n",
    "#         Since this parameter is needed for every extraction, I didn't want\n",
    "#         to re-explain it in all examples. What do you think?\n",
    "\n",
    "# Threshold on the spatial profile. \n",
    "# Only pixels above this threshold will be used for extraction.\n",
    "# (for at least one order)\n",
    "params[\"thresh\"] = 1e-4  # Same units as the spatial profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate extraction object\n",
    "(This needs to be done only once unless the oversampling (`n_os`) changes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": " Please specify `orders` argumnent.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-a939417f2884>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrpzOverlap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mref_files_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ongenesis/github/jwst-mtl/SOSS/extract/overlap.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, p_list, lam_list, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m         \u001b[0;31m# Init upper class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1709\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_lo_hi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ongenesis/github/jwst-mtl/SOSS/extract/overlap.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, p_list, lam_list, t_list, c_list, data, lam_grid, lam_bounds, i_bounds, c_kwargs, sig, n_os, mask, thresh, orders, verbose, scidata)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Raise error if the number of orders is not consitent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ord\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" Please specify `orders` argumnent.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Shape of the detector used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m:  Please specify `orders` argumnent."
     ]
    }
   ],
   "source": [
    "extract = TrpzOverlap(*ref_files_args, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best tikhonov factor\n",
    "This takes some time, so it's better to do it once if the exposures are part of a time series observation, i.e. observations of the same object at similar SNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which factors to tests.\n",
    "factors = np.logspace(-25, -12, 14)\n",
    "\n",
    "# Noise estimate to weigh the pixels.\n",
    "# Poisson noise + background noise.\n",
    "sig = np.sqrt(data + bkgd_noise**2)\n",
    "\n",
    "# Tests all these factors.\n",
    "tests = extract.get_tikho_tests(factors, data=data, sig=sig)  # TODO sig is the uncertainty on the date here so it might be good to call it that?\n",
    "\n",
    "# Find the best factor.\n",
    "best_fac = extract.best_tikho_factor(tests=tests, i_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine the grid (span 4 orders of magnitude).\n",
    "best_fac = np.log10(best_fac)\n",
    "factors = np.logspace(best_fac-2, best_fac+2, 20)\n",
    "\n",
    "# No need to specify `data` and `sig` again. \n",
    "# TODO: why not? Wouldn't it be better to require that to avoid confusion?\n",
    "# Answer: When a reference file or science file is specified, the class keeps it\n",
    "#         as an attribute. When an extraction is called, it is updated if specified.\n",
    "#         It is done to save some text when iterating on the spatial profile, for\n",
    "#         example, and to save time (some matrix multiplications don't need to be \n",
    "#         re-computed). But I'm open to discuss it!\n",
    "tests = extract.get_tikho_tests(factors, data=data, sig=sig)\n",
    "best_fac = extract.best_tikho_factor(tests=tests, i_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the oversampled spectrum $f_k$\n",
    "TODO explain what f_k is. <br>\n",
    "I was thinking of explaining f_k in another notebook or text?\n",
    "I didn't want to re-explain it in all examples. What do you think?\n",
    "\n",
    "Can be done in a loop for a timeseries and/or iteratively for different estimates of the reference files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the spectrum.\n",
    "f_k = extract.extract(data=data, sig=sig, tikhonov=True, factor=best_fac)  \n",
    "# Could we make change this method to __call__?\n",
    "# Very good idea!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the extracted spectrum.\n",
    "plt.plot(extract.lam_grid, f_k)\n",
    "\n",
    "plt.xlabel(\"Wavelength [$\\mu m$]\")\n",
    "plt.ylabel(\"Oversampled Spectrum $f_k$ [energy$\\cdot s^{-1} \\cdot \\mu m^{-1}$]\")\n",
    "# For now, arbitrairy units, but it should be the flux that hits the detector,\n",
    "# so energy/time/wavelength\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin to pixel native sampling\n",
    "To get a result comparable to typical extraction methods, we need to integrate the oversampled spectrum ($f_k$) to a grid representative of the native pixel sampling (for each order). This integration is done according to the equation\n",
    "\\begin{equation}\n",
    "\\mathrm{bin}_{i} = \\int_{\\lambda_{ni}^-}^{\\lambda_{ni}^+} T_n(\\lambda)\\tilde{f}_n(\\lambda)\\lambda d\\lambda \\, ,\n",
    "\\end{equation}\n",
    "where $n$ is a given order, $T_n$ is the throughput of the order and $\\tilde{f}_n$ is the underlying flux convolved to the order $n$ resolution. The result of this integral will be in fake counts (it is not directly the sum of the counts so that's why I call it fake). \n",
    "\n",
    "One could directly extract the integrated flux by setting the throughput to $T_n(\\lambda) = 1$ (see second example). The result would then be in flux units instead of counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bin in counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output in a list for different orders.\n",
    "\n",
    "f_bin_list = []  # Integrated flux.\n",
    "lam_bin_list = []  # Wavelength grid.\n",
    "\n",
    "for i_ord in range(extract.n_ord): # TODO I think we can make it so we just get the order m=1,2 and never have to deal with an index as well.\n",
    "    \n",
    "    # Integrate.\n",
    "    lam_bin, f_bin = extract.bin_to_pixel(f_k=f_k, i_ord=i_ord)\n",
    "    \n",
    "    # Save.\n",
    "    f_bin_list.append(f_bin)\n",
    "    lam_bin_list.append(lam_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, sharex=True, figsize=(12,6))\n",
    "\n",
    "for i_ord in range(extract.n_ord):\n",
    "    label = extract.orders[i_ord]\n",
    "    ax[i_ord].plot(lam_bin_list[i_ord], f_bin_list[i_ord], label=label)\n",
    "    \n",
    "ax[0].set_ylabel(\"Extracted signal [counts]\")\n",
    "    \n",
    "ax[1].set_xlabel(\"Wavelength [$\\mu m$]\")\n",
    "ax[1].set_ylabel(\"Extracted signal [counts]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bin in flux units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set throughput to 1\n",
    "def throughput(x):\n",
    "    return np.ones_like(x)\n",
    "\n",
    "for i_ord in range(extract.n_ord): # TODO I think we can make it so we just get the order m=1,2 and never have to deal with an index as well.\n",
    "    \n",
    "    # Integrate.\n",
    "    lam_bin, f_bin = extract.bin_to_pixel(f_k=f_k, i_ord=i_ord, throughput=throughput)\n",
    "    \n",
    "    # Plot\n",
    "    label = extract.orders[i_ord]\n",
    "    plt.plot(lam_bin_list[i_ord], f_bin_list[i_ord], label=label)\n",
    "\n",
    "plt.ylabel(r\"Convolved flux $\\tilde{f_k}$ [energy$\\cdot s^{-1} \\cdot \\mu m^{-1}$]\")  \n",
    "plt.xlabel(\"Wavelength [$\\mu m$]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(title=\"Order\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild the detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebuilt = extract.rebuild(f_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(111, aspect='equal')\n",
    "\n",
    "plt.pcolormesh((rebuilt - data)/sig, vmin=-3, vmax=3)\n",
    "\n",
    "plt.colorbar(label=\"Error relative to noise\", orientation='horizontal', aspect=40)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we are very close to the photon noise limit in this case. There are some small structures in the 2nd order in the overlap region, but the extracted spectrum is dominated by the 1st order in this wavelength region anyway, due to the higher throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
